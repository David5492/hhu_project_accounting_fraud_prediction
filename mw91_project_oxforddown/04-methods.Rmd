---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
documentclass: book
bibliography: references.bib
---

# Methoden {#methods} 

Diese Arbeit vergleicht die Vorhersagequalität der in der Accounting Fraud Detection gängigen logistischen Regression nach Dechow et al. (vgl. Bao et al. 2020, S. 2) mit der von neuronalen Netzen.
Die logistische Regression ist eng mit der linearen Regression verwandt und wird zur binären Schätzung einer Klassenzugehörigkeit verwandt (vgl. Géron 2019, S. 144). Dabei berechnet sie eine gewichtete Summe von Inputfaktoren und aggregiert sie zu einer Wahrscheinlichkeit zwischen 0 und 1. Liegt diese Wahrscheinlichkeit bei mindestens 0.5, so wird die Klasse „1“ vorhergesagt, welcher in dieser Arbeit der Klasse „fraud“ entspricht (vgl. Géron 2019, S. 144). Hierzu wird für jedes Attribut einer Beobachtung eine Sigmoid-Funktion verwendet, welche S-förmig vom Minimum bis zum Maximum des jeweiligen Attributs verläuft und die Verteilungen der Merkmalsausprägungen möglichst gut nach Klassenzugehörigkeit abgrenzt. Je weiter eine Merkmalsausprägung von dieser Grenze entfernt ist, desto näher ist der Funktionswert an der 1 oder der 0 (vgl. Géron 2019, S. 148).
Neuronale Netze bestehen aus drei Sorten von Schichten: Input-Schichten, welche Daten einlesen, versteckte Schichten, welche die Daten verarbeiten und Output-Schichten, welche aus den verarbeiteten Daten eine Prognose ableiten (vgl. Géron 2019, S. 286). In dieser Arbeit besteht die Output-Schicht aus lediglich einem Knoten, welche die Klassen „fraud“ abbildet. Die Anzahl der Knoten der Input-Schicht entspricht der Anzahl der Variablen im Datensatz. Die Knoten einer Schicht sind jeweils mit jedem Knoten seiner nachfolgenden Schicht durch „Gewichte“ verbunden. Jeder einzelne Knoten aggregiert die Signale, die er empfängt über deren Gewichte zu einer Zahl und wendet eine Aktivierungsfunktion an (vgl. Géron 2019, S. 282). Übersteigt der Funktionswert einen gegeben Schwellenwert, so „feuert“ das Neuron, was bedeutet, dass es ein Signal größer 0 an die Neuronen der nächsten Schicht weitergibt (vgl. Géron 2019, S. 282-283). Die Gewichte und alle Schwellenwerte werden durch Backpropagation unter Zuhilfenahme des Gradient Descent Algorithmus verbessert (vgl. Géron 2019, S.119 und S, 286). Sind alle Trainingsdaten einmal zum Training herangezogen worden, bedeutet das, dass das Netz für „eine Epoche“ trainiert wurde (vgl. Géron 2019, S. 127). In dieser Arbeit wird ein Netz über 100 Epochen hinweg trainiert.


 AB HIER HANDELT SICH DER AUFSCHRIEB MEHR UM NOTIZEN ALS UM EINE ABGABEFÄHIGE VERSION.

```{r, include=FALSE}
# install.packages("stringi", type="binary")
# install.packages('caret')
# install.packages('neuralnet')
# install.packages('dplyr')
# install.packages('Hmisc')
# install.packages('smotefamily')
# install.packages('readr')
# install.packages('rio', type='binary')
# install.packages('bookdown', type='binary')

library(neuralnet)
library(caret)
library(dplyr)
library(Hmisc)
library(smotefamily)
library(readr)
library(rio)
```
TODO:

  1. Evaluate-Funktion bilden
  2. LogReg mit allen Daten. Ablauf: 
      1. Train-test-Split (X_train, y_train, X_test, y_test)
      2. SOMTE in X_train anwenden, seed = 42
      3. Training
      4. Prediction (in y_pred speichern)
      5. Evaluate-Funktion anwenden
  3. LogReg mit Rohdaten
      1. ...
  4. LogReg mit Ratios
      1. ...
  5. Summary von allen 3 Modellen

```{r}

## 1. EVALUATE BILDEN

evaluate <- function(test, pred){
  
  pred <- ifelse(pred > 0.5, 1, 0)
  confusion <- table(test, pred)
  
  TP <- confusion[2,2]
  FP <- confusion[1,2]
  FN <- confusion[2,1]
  
  total_acc <- numeric(2)
  total_acc[1] <- NaN
  total_acc[2] <- round((confusion[1,1] + confusion[2,2]) / sum(confusion),4)

  prec <- numeric(2)
  prec[1] <- NaN
  prec[2] <- round(TP / (TP + FP),4)
  
  sens <- numeric(2)
  sens[1] <- NaN
  sens[2] <- round(TP / (TP + FN),4)
  
  F1 <- numeric(2)
  F1[1] <- NaN
  F1[2] <- round(2*(prec[2]*sens[2])/(prec[2] + sens[2]), 4)
  
  F2 <- numeric(2)
  F2[1] <- NaN
  F2[2] <- round((1 + 2^2) * (prec[2]*sens[2]) / (2^2 * prec[2] + sens[2]), 4)
  
  F.5 <- numeric(2)
  F.5[1] <- NaN
  F.5[2] <- round((1 + 0.5^2) * (prec[2]*sens[2]) / (0.5^2 * prec[2] + sens[2]), 4)
  
  print(cbind(confusion, total_acc, prec, sens, F1, F2, F.5))
  
}
```



```{r}
## 2. MODELL MIT ALLEN DATEN TRANIEREN

train_test_split_smote<- function(data, y_col, frac = 0.7, seed = 42, k = 5){
  set.seed(seed)
  
  smp_size <- floor(frac * nrow(data))
  train_ind <- sample(seq_len(nrow(data)), size = smp_size)
  
  X_smote <- data[train_ind, -match(y_col, names(data))]
  y_smote <- data[train_ind, match(y_col, names(data))]
  
  true_frac <- sum(y_smote) / length(y_smote)
  
  train_smote_object <- SMOTE(X_smote, y_smote, K = 5, dup_size = 1 / true_frac)$data
  
  X_train <- train_smote_object[,-match('class', names(train_smote_object))]
  y_train <- as.numeric( train_smote_object[,match('class', names(train_smote_object))])
  
  X_test <- data[-train_ind, -match(y_col, names(data))]
  y_test <- data[-train_ind, match(y_col, names(data))]
  
  return(list(X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test))
}

splitted_data <- train_test_split_smote(data = all_data, y_col = 'misstate', frac = 0.7)

X_train <- splitted_data$X_train
X_test <- splitted_data$X_test
y_train <- splitted_data$y_train
y_test <- splitted_data$y_test

train <- X_train
train$misstate <- y_train

logit_all_data <- glm(misstate ~., data = train, family = "binomial")
y_pred_logit_all_data <- predict.glm(logit_all_data, X_test)

evaluate(y_test, y_pred_logit_all_data)

```
```{r}
summary(logit_all_data)
```



```{r}
## 2. MODELL MIT ROH-DATEN TRANIEREN

splitted_data <- train_test_split_smote(data = raw_data, y_col = 'misstate', frac = 0.7)

X_train <- splitted_data$X_train
X_test <- splitted_data$X_test
y_train <- splitted_data$y_train
y_test <- splitted_data$y_test

train <- X_train
train$misstate <- y_train

logit_raw_data <- glm(misstate ~., data = train, family = "binomial")
y_pred_logit_raw_data <- predict.glm(logit_raw_data, X_test)

evaluate(y_test, y_pred_logit_raw_data)
```
```{r}
summary(logit_raw_data)
```


```{r}
## 3. MODELL MIT RATIO-DATEN TRANIEREN

splitted_data <- train_test_split_smote(data = ratio_data, y_col = 'misstate', frac = 0.7)

X_train <- splitted_data$X_train
X_test <- splitted_data$X_test
y_train <- splitted_data$y_train
y_test <- splitted_data$y_test

train <- X_train
train$misstate <- y_train

logit_ratio_data <- glm(misstate ~., data = train, family = "binomial")
y_pred_logit_ratio_data <- predict.glm(logit_ratio_data, X_test)

evaluate(y_test, y_pred_logit_ratio_data)
```
```{r}
summary(logit_ratio_data)
```










